<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8"/>
	<meta http-equiv="X-UA-Compatible" content="IE=9" />
	<link rel="stylesheet" type="text/css" href="../../css/styles.css" />
	<link rel="stylesheet" type="text/css" href="../../css/snippet.css" />
	<script type="text/javascript" src="../../scripts/snippet.js"></script>	
	<script type="text/javascript" src="../../scripts/jquery.util.js" charset="utf-8"></script>
	<script type="text/javascript" src="../../scripts/common.js" charset="utf-8"></script>
	<script type="text/javascript" src="../../scripts/core.js" charset="utf-8"></script>
	<script type="text/javascript" src="../../scripts/search.js" charset="utf-8"></script>
  <title>Optimizing Application Performance</title> 
 </head> 
 <body onload="prettyPrint()" style="overflow: auto;">
 
 <div id="toc-navigation">
	<div id="profile">
		<p><img alt="Mobile native" src="../../images/mobile_s_n.png"/> <img alt="Wearable native" src="../../images/wearable_s_n.png"/></p>
	</div>
	
	<div id="toc_border"><div id="toc">
		<p class="toc-title">Content</p>
		<ul class="toc">
			<li><a href="#measure">Measuring Application Performance</a></li>
			<li><a href="#performance">Performance Tips</a></li>
			<li><a href="#dynamic_analysis">Dynamic Analysis</a></li>
			<li><a href="#valgrind_analysis">Valgrind Analysis</a></li>			
		</ul>
		
		<p class="toc-title">Related Info</p>
		<ul class="toc">
			<li><a href="../../../../org.tizen.devtools/html/common_tools/da_overview.htm">Dynamic Analyzer</a></li>
			<li><a href="../../../../org.tizen.devtools/html/native_tools/valgrind_n.htm">Valgrind</a></li>
			</ul>
	</div></div>
</div>	

<div id="container"><div id="contents"><div class="content">
  <h1>Optimizing Application Performance</h1> 
  
  <p>The application performance optimization features include measuring and improving application performance.</p>
  
  <p>If an application performs poorly and gives delayed responses to user actions, the user experience can suffer. To avoid this situation, some parts of the code must be optimized.</p>
  
  <p>Most processors that are used today in mobile phones are based on multi-core technologies and so you must consider utilizing this hardware feature. To effectively utilize multi-core capabilities, you need to divide your code to run on several cores simultaneously. Traditionally, this is done by using <span style="font-family: Courier New,Courier,monospace">pthreads</span>, but this method has an overhead of initialization and termination of threads, and can generate potential runtime errors. Several solutions exist to exploit multi-core capabilities easily. These solutions abstract <span style="font-family: Courier New,Courier,monospace">pthreads</span>, allowing you to focus on the native application development without worrying about thread level management.</p> 

  <p>To improve the performance of an application:</p> 
  <ol> 
   <li>Identify the bottlenecks which need to be optimized.</li> 
   <li>Optimize the bottlenecks by code refactoring.</li> 
   <li><a href="#measure">Measure performance</a> to compare refactoring gains.</li> 
   <li>If the performance goal is met, you can stop the process, else go to step 2 and repeat till the goal is met.</li> 
  </ol> 
  <h2 id="measure" name="measure">Measuring Application Performance</h2> 
  <p>Tizen SDK supports various tools which help to measure performance and increase performance at runtime:</p> 
  <ul>
	<li><a href="../../../../org.tizen.devtools/html/common_tools/da_overview.htm">Dynamic Analyzer</a>
	<p>Dynamic Analyzer helps to identify bottlenecks and improve resource usage patterns in native applications. For more information on its usage, see <a href="#dynamic_analysis">Dynamic Analysis</a>.</p></li>

	<li><a href="../../../../org.tizen.devtools/html/native_tools/valgrind_n.htm">Valgrind</a> <p>Valgrind detects memory errors or leaks. This tool helps to improve memory usage patterns in native applications. For more information on its usage, see <a href="#valgrind_analysis">Valgrind Analysis</a>.</p></li>
  </ul>
  <p>Measuring performance allows you to identify bottlenecks that take a critical amount of time during the program execution and to compare the code execution time before and after optimization.</p> 
  <p>Profiling can show unexpected bottleneck locations that you have not noticed otherwise. Once bottlenecks are identified, you can consider applying threading mechanism to clear them. This solution does not work in all situations or for all algorithms, but it can be worth spending your time to investigate the possibilities. Code refactoring is required to apply the threading mechanism.</p> 
  
  <h2 id="performance" name="performance">Performance Tips</h2> 
  <p>A faster application can increase battery life. If your application is not as fast as expected, you can look at profiling data to identify bottlenecks. Fixing these bottlenecks increases the application speed with minimal effort.</p> 
  <p>Some general tips to improve the performance of your application are:</p> 
  <ul> 
   <li>Select the right algorithm and data structures.</li> 
   <li>High-level optimization is important because it can change the order of complexity. If your code includes <span style="font-family: Courier New,Courier,monospace">sort</span>, <span style="font-family: Courier New,Courier,monospace">search</span>, or <span style="font-family: Courier New,Courier,monospace">compare</span>, use optimal algorithms and data structures.</li> 
   <li>Split a task which contains both high and low priority jobs to prevent low priority jobs delaying high priority jobs. Running high and low priority jobs in a single task causes delays.</li> 
   <li>Do not run heavy calculations in the same thread as your GUI.</li> 
   <li>Use optimization options provided by toolchains.</li> 
  </ul> 

 
 
 <h2 id="dynamic_analysis" name="dynamic_analysis">Dynamic Analysis</h2> 
  <p>To make your applications powerful, faster, and more stable, you need to analyze their performance to recognize and fix bottlenecks, bugs, and memory and resource leaks.</p> 
  <p>The following instructions and examples help you to use the dynamic analyzer effectively:</p> 
  <ul> 
   <li><a href="#running">Running Dynamic Analyzer</a> <p>Describes how to launch the dynamic analyzer.</p></li> 
   <li><a href="#result">Using the Analysis Result</a> <p>Describes how to utilize the dynamic analyzer for various improvement purposes.</p></li> 
   
  </ul>
  
    <h3 id="running" name="running">Running Dynamic Analyzer</h3> 
  <p>You can launch the dynamic analyzer in the IDE or as a standalone application from the Tizen SDK submenu.</p> 
  <p>To launch the dynamic analyzer in the IDE:</p> 
  <ol> 
   <li>Right-click your project in the Tizen IDE <strong>Project Explorer</strong> view.</li> 
   <li>Select <strong>Profile As &gt; Profile with Dynamic Analyzer</strong>. <p>The selected project is built, packaged, and installed on the target device. The dynamic analyzer is launched and the profiling starts automatically.</p></li> 
  </ol> 
  <p>To run the dynamic analyzer as a standalone from the Tizen SDK menu:</p> 
  <ol> 
   <li>Launch the dynamic analyzer from the SDK submenu.</li> 
   <li>Select the target device and the application to be traced from the combo box in the dynamic analyzer toolbar.</li> 
   <li>Click the <strong>Trace Start</strong> button.</li> 
  </ol> 
  <p>The performance details of your application retrieved during tracing are stored in trace files. You can manage the trace files through the <strong>Toolbar</strong>.</p> 
  <p>The following figure illustrates the components of the <strong>Toolbar</strong> used for running the dynamic analyzer.</p> 
  <p class="figure">Figure: Toolbar</p> 
  <p align="center"> <img alt="Toolbar" src="../../images/coolbar.png" /> </p> 
  <ol> 
   <li><strong>Target</strong> 
   <p>The <strong>Target</strong> combo box shows a serial number (if the target is a device), or the Emulator name (if the target is the Emulator).</p> </li>
   <li><strong>Application</strong> 
   <p>The <strong>Application</strong> combo box contains a list of applications in the selected target.</p> 
   <p>If the <strong>Target</strong> combo box is empty or disabled, the <strong>Application</strong> combo box is disabled.</p></li> 
   <li><strong>Start/Stop</strong>
   <p>The <strong>Start/Stop</strong> button starts or stops the tracing of the selected application. While tracing, the trace result and UI sequence is automatically recorded and temporarily saved. To store the record permanently, click <strong>Save Trace</strong>.</p> </li> 
   <li><strong>Timer</strong>
   <p>The timer starts when you click the <strong>Start</strong> button and updates every second. It shows the current running time of the dynamic analyzer. If you click <strong>Stop</strong>, the timer stops when the analysis processing is complete.</p> </li> 
   <li><strong>Save Trace</strong>
   <p>Clicking the <strong>Save Trace</strong> button saves the trace data permanently.</p> </li> 
   <li><strong>Open Trace</strong> 
   <p>Clicking the <strong>Open Trace</strong> button loads and displays the saved trace data.</p> 
   <p align="center"> <img alt="Open Trace window" src="../../images/open_trace.png" /> </p> 
   <p>The <strong>Open Trace</strong> window consists of the following panels:</p> 
   <ul> 
    <li><strong>Saved file</strong> 
    <p>Shows the trace saved by clicking the <strong>Save Trace</strong> button.</p> 
    <p>An invalid save version trace is shown in orange color and cannot be opened. A valid trace is shown in black color. The currently opened trace is shown in blue color.</p> </li>
    <li><strong>Temporary file</strong>
    <p>Shows the temporary traces. A temporary trace refers to a trace that has not been saved and is deleted when the program exits.</p> </li> 
    <li><strong>Trace details</strong> 
    <p>Shows trace information of the saved traces from the <strong>Saved file</strong> and <strong>Temporary file</strong> panels.</p> </li>
   </ul> 
   <p>To open a trace, double-click the trace or select the trace and click <strong>Open</strong>.</p> 
   <p>To delete a trace, select the trace and click the delete key on your keyboard.</p> </li>
   <li><strong>Replay</strong>
   <p>Clicking <strong>Replay</strong> repeats a previous analysis. You can use data from a previous dynamic analyzer instance or a saved trace data file. If the target or application do not match, the button is disabled.</p> </li> 
   <li><strong>Process</strong>
   <p>The <strong>Process</strong> combo box has a process list of the application being traced. By default, the dynamic analyzer shows the analysis results of all processes. If you select a process in the list, the dynamic analyzer shows the analysis result of that process only.</p></li>
    <li><strong>View Source</strong>
   <p>The <strong>View Source</strong> button displays the source code. If you click the button and the mouse is on the method name in any table-like view, the source code is displayed as a tooltip. By double-clicking the tooltip you can see the source code in the IDE. Apart from the Callstack view, the source code displayed is the caller part of the selected API, not the API definition.</p>

 <p>If an API is called from a shared library, the source code is not displayed as the source code of the shared library is not available.</p> 

  <p>In the <strong>Callstack</strong> view, the source code corresponding to the address of the selected callstack unit is displayed.</p> 

        <table class="note"> 
         <tbody> 
          <tr> 
           <th class="note">Note</th> 
          </tr> 
          <tr> 
           <td class="note"> <p>If the source code exists outside Tizen IDE, for example, in a built-in application on a device, the <strong>View Source</strong> button is disabled. The source view is available only for applications which are built as normal native projects in the IDE on the local machine.</p></td> 
          </tr> 
         </tbody> 
        </table></li> 
	<li><strong>Capture screen</strong>
   <p>The <strong>Capture screen</strong> button captures the screen of the target at the time. The screenshot is shown in the <strong>Snapshot</strong> view.</p></li>  
  <li><strong>Settings</strong>
   <p>The <strong>Settings</strong> button opens the <strong>Settings</strong> window. It supports the runtime configuration feature and other settings.</p></li>
   <li><strong>About</strong> 
   <p>The <strong>About</strong> button opens the <strong>About</strong> window, which displays the dynamic analyzer version, build time, and license.</p> </li>
  </ol> 
 
<h3 id="result" name="result">Using the Analysis Result</h3> 
  <p>After the profiling is terminated by the dynamic analyzer, analyze the result. The dynamic analyzer provides a variety of information collected while your application was run. Use the result selectively to meet your improvement purposes.</p>
  <p>The following instructions help you to utilize the analysis result:</p>
  <ul>
   <li><a href="#performance_analysis">Performance Analysis</a> <p>Describes how to analyze application performance.</p></li> 

   <li><a href="#detecting">Detecting Leaks</a> <p>Describes how to detect memory and resource leaks.</p></li> 
   <li><a href="#multithread">Multi-threaded Application and Synchronization Analysis</a> <p>Describes how to analyze threads and synchronization.</p></li> 
  </ul>

<h4 id="performance_analysis" name="performance_analysis">Performance Analysis</h4> 
  <p>You can use the dynamic analyzer to analyze application performance and identify bottlenecks. After identifying bottlenecks, you can modify the code to eliminate them, which increases application performance significantly, and extends the battery life of the device running the application.</p> 
 
  <p>To analyze performance of the application with the dynamic analyzer, use the following features:</p> 
  <ul> 
   <li>User Function Profiling 
    <p>When analyzing application performance, execution time of each method is one of the most significant factors. You can improve the performance of an application by identifying unexpected bottleneck locations, and analyzing and optimizing the most used methods in the dynamic analyzer.</p> 
  <p>To detect and fix the methods consuming the most time:</p> 
  <ol> 
   <li>Select the <a href="../../../../org.tizen.devtools/html/common_tools/da_summary.htm">Summary</a> tab and view the <strong>Function Usage Profiling</strong> view displaying the methods consuming the most time. Click the title of a column to view the sorted results.</li> 

   <li>To view the execution time of the methods called within a specific time period, use the <a href="../../../../org.tizen.devtools/html/common_tools/da_range_info.htm">range information feature</a> of the dynamic analyzer. 
   	<p>The time consumed by UI-related methods is displayed on the <strong>UI Function Profiling</strong> view of the <strong>UI</strong> tab.</p> </li>
  </ol>  
   </li> 
   <li>Timeline CPU Chart 
   <p>When analyzing application performance, the CPU load is one of the most significant factors. A CPU load peak can result in a performance bottleneck. High CPU load leads to increased memory consumption, which shortens the battery life of the device running the application. To avoid this, you need to optimize your code.</p> 
  <p class="figure">Figure: Timeline CPU chart</p> 
  <p align="center"><img alt="Timeline CPU chart" src="../../images/timeline_cpu_chart.png" style="display: block; text-align: center; margin-left: auto; margin-right: auto" /></p> 
  <p>To detect and fix CPU load peaks with the CPU load feature of the dynamic analyzer:</p> 
  <ol> 
   <li>Select the <strong>Timeline</strong> tab and view the CPU chart.</li> 
   <li>Hover the mouse on a CPU peak to view the CPU load value in a tooltip.</li> 
   <li>Click the CPU peak to highlight the last user method called before the peak in the <strong>Call Trace</strong> view.</li> 
   <li>Click the <strong>View Source</strong> button and place the mouse on the highlighted method. The source code is displayed as a tooltip. To investigate the method, double-click on it, and the source code is displayed in the IDE.</li> 
   <li>Modify the code in the IDE, re-build, and re-analyze the application to see if the bottleneck has been eliminated.</li> 
  </ol> 
   
   </li> 
   <li>Thread Load 
     <p>If you use threads in your application code, you need to analyze the load of each thread during the application execution. The thread load feature helps to distribute the thread load. You can modify the code to optimize the thread load, while maintaining a single thread.</p> 
  <p>The thread load is displayed in the <strong>Thread</strong> tab.</p> 
  <p class="figure">Figure: Thread load</p> 
  <p align="center"><img alt="Thread load" src="../../images/thread_load.png" style="display: block; text-align: center; margin-left: auto; margin-right: auto" /></p> 
  <p>The thread line displayed in blue indicates the thread load within a time frame. The darker the color, the higher the load.</p>
   
   </li> 
  </ul> 
  <p>When modifying the application code to improve its performance, consider the following:</p> 
  <ul> 
   <li>Select the right algorithm and data structures.</li> 
   <li>High-level optimization is important because it can change the order of complexity. If your code includes <span style="font-family: Courier New,Courier,monospace">sort</span>, <span style="font-family: Courier New,Courier,monospace">search</span>, or <span style="font-family: Courier New,Courier,monospace">compare</span>, use optimal algorithms and data structures.</li> 
   <li>Running high and low priority jobs in a single task causes delays. Split the jobs into multiple tasks.</li> 
   <li>Do not run heavy calculations in the same thread with your GUI.</li> 
   <li>Use optimization options provided by toolchains.</li> 
  </ul> 

 
 <h4 id="detecting" name="detecting">Detecting Leaks</h4> 
  <p>To improve the performance of your application, you can use the dynamic analyzer to detect memory leaks.</p> 

  <p>Memory leaks occur when memory capacity that is dynamically allocated during application execution is not returned after the execution stops. Severe or accumulating memory leaks can affect the performance of other applications and programs.</p> 
  <p>To detect and fix memory leaks using the dynamic analyzer:</p> 
  <ol> 
   <li>To view the memory leaks occurring during application analysis, select the <a href="../../../../org.tizen.devtools/html/common_tools/da_summary.htm">Summary</a> tab.
  <p align="center"><img alt="Memory leaks" src="../../images/memory_leaks.png" /></p> 
   <p>All the listed items are not memory leaks. To identify actual memory leaks, look for applications that are already terminated but have not returned the allocated memory. When these leaks are fixed, they disappear from the list.</p></li> 
   <li>Click the <strong>View Source</strong> icon in the toolbar. 
   <p align="center"><img alt="View source" src="../../images/view_source.png" /></p></li> 
   <li>Move the mouse pointer to the list item you want to check. The source code is displayed as a tooltip. The part causing the memory leak is displayed in red. 
   	<p align="center"><img alt="Source View" src="../../images/source_view.png" /></p>
   	</li> 
   <li>To view the entire source code in the IDE and fix the leak, double-click the list item. If the IDE is not running the dynamic analyzer launches it automatically.</li> 
  </ol> 
 
 <h4 id="multithread" name="multithread">Multi-threaded Application and Synchronization Analysis</h4> 
  <p>Understanding the thread execution in multi-threaded applications can be challenging. The GDB (GNU Debugger) supports the process of debugging multi-threaded applications, but since it uses synchronization objects, the debugging can be quite difficult. 
  	The dynamic analyzer, on the other hand, provides effective thread analysis features.</p> 
  <p>You can use the dynamic analyzer to:</p> 
  <ul> 
   <li><a href="#life">Analyze thread life-cycle</a></li> 
   <li><a href="#concurrency">Analyze thread concurrency</a></li> 
   <li><a href="#sync">Analyze synchronization</a></li> 
  </ul> 
  <h5 id="life" name="life">Analyzing Thread Life-cycle</h5> 
  <p>Testing threads is difficult as they are nondeterministic. Visualizing the thread life-cycle is an effective method for analyzing the thread life-cycle. </p> 
  <p>The dynamic analyzer has 3 types of user threads:</p> 
  <ul> 
   <li><strong>Main thread</strong> created from the system for running applications</li> 
   <li><strong>Tizen threads</strong> including worker threads and event-driven threads</li> 
   <li><strong>pthread</strong></li> 
  </ul> 
  <p>In the thread chart, the thread life-cycle is displayed as follows:</p> 
  <ul> 
   <li><strong>Thread creation</strong>: When an API is called to create the thread, a yellow bar is displayed and a new chart item is created with a <span style="font-family: Courier New,Courier,monospace">tid</span> arrow. <p class="figure">Figure: Creating a thread</p> 
<p align="center"><img alt="thread create" src="../../images/thread_create.png" /></p></li> 
   <li><strong>Thread exiting</strong>: When a thread exits, a purple bar is displayed with a joined <span style="font-family: Courier New,Courier,monospace">tid</span> arrow. If another thread calls the API of the exited thread, a yellow bar is displayed. <p class="figure">Figure: Exiting a thread</p> 
<p align="center"><img alt="thread exit" src="../../images/thread_exit.png" /></p></li> 
  </ul> 
  <p>A new thread is created in a joinable state. Otherwise, memory and resource leaks can occur until the process ends. To make the process faster, set the thread to the detach state, or call the detach API. You can check the state of the thread on the <strong>Thread</strong> tab.</p> 
  <h5 id="concurrency" name="concurrency">Analyzing Thread Concurrency</h5> 
  <p>The number of live threads and their resource usage can be used to determine an efficient thread concurrency.</p> 
  <p>The thread chart displays the relationship and progress between threads and allows you to check the number of live threads. The CPU load of a thread is also displayed.</p> 
  <h5 id="sync" name="sync">Analyzing Synchronization</h5> 
  <p>When multiple threads access the same resources, data race occurs. To avoid this, threads must be synchronized.</p> 
  <p>The synchronization chart in the dynamic analyzer has the following synchronization objects:</p> 
  <ul> 
   <li>Tizen mutex</li> 
   <li>Tizen monitor</li> 
   <li>Tizen semaphore</li> 
   <li>pthread mutex</li> 
   <li>pthread condition variable</li> 
  </ul> 
  <p>You can view the synchronization chart based on the thread, or the synchronization status:</p> 
  <ul> 
   <li> To view the child of each thread chart item, select <strong>Thread</strong> in the synchronization chart combo box. </li> 
   <li>To view the parent item with the thread for each usage showing the child items, select <strong>Sync</strong>.</li> 
  </ul> 
  <p class="figure">Figure: Synchronization chart types</p> 
  <p align="center"><img alt="Synchronization chart types" src="../../images/sync_chart.png" /></p> 
  <p>A synchronization object can be checked using the synchronization chart. When a synchronization object acquires a lock, the thread enters the critical section. The dynamic analyzer analyzes the critical section duration and waiting time. </p> 
  <p>If the critical section duration increases, the thread stops working concurrently and affects the performance. If a thread acquires a lock, the critical section waiting time of the other threads increases. To avoid potential dead lock, reduce the waiting time.</p> 
  <p class="figure">Figure: Dead lock warning</p> 
 <p align="center"><img alt="Dead lock warning" src="../../images/dead_lock_warning.png" /></p> 
  
<h2 id="valgrind_analysis" name="valgrind_analysis">Valgrind Analysis</h2> 
  <p>Valgrind helps you to detect memory errors or leaks in your application at runtime.</p> 
  <p>The following instructions and examples help you to use the Valgrind effectively:</p> 
  <ul> 
   <li><a href="#running_valgrind">Running Valgrind</a> <p>Describes how to launch the Valgrind with your application.</p></li> 
   <li><a href="#valgrind_result">Viewing Valgrind Result</a> <p>Describes the information of the result analyzed by Valgrind.</p></li> 
  </ul> 

 <h3 id="running_valgrind" name="running_valgrind">Running Valgrind</h3> 
   <p>To set the Valgrind options for your application:</p> 
  <ol> 
   <li>In the <strong>Project Explorer</strong> view, right-click the project and select <strong>Profile As</strong> &gt; <strong>Profile Configurations</strong>.</li> 
   <li>In the <strong>Profile Configurations</strong> window, right-click the <strong>Profile with Valgrind</strong> and select <strong>New</strong>.</li> 
   <li>Select the created configuration.</li> 
   <li>Go to <strong>Memory Profile Options &gt; Collect data</strong> tab: <p>Select from 2 types of memory profiling settings:</p> 
    <ul> 
     <li>Memory error and memory leak checking <p>This option uses the <strong>Memcheck</strong> tool to profile your application.</p> </li> 
     <li>Heap memory profiling <p>This option uses the <strong>Massif</strong> tool to profile your application. 
       </p></li> 
    </ul></li> 
   <li><p>On the <strong>General setting</strong> tab, set the general Valgrind options. These options are used for both <strong>Memcheck</strong> and <strong>Massif</strong> profiling.</p> <p class="figure">Figure: Memory error and memory leak data options</p> 
<p align="center"><img alt="Memory error and memory leak data options" src="../../images/valgrind_general.png" style="display: block; text-align: center; margin-left: auto; margin-right: auto" /></p> 
    <table style="width: 100%" border="1"> 
     <caption>
       Table: General setting options 
     </caption> 
     <tbody> 
      <tr> 
       <th rowspan="1" style="text-align:center;margin-left:auto;margin-right:auto;">Option name</th> 
       <th colspan="1" style="text-align:center;margin-left:auto;margin-right:auto;">Description</th> 
      </tr> 
      <tr> 
       <td>trace children on exec</td> 
       <td><p>When enabled, Valgrind traces into sub-processes initiated through the exec system call. This is necessary for multi-project applications. Valgrind does trace into the child of a fork (it would be difficult not to, since fork makes an identical copy of a process), so this option is arguably badly named. However, most children of fork calls immediately call exec anyway.</p> </td> 
      </tr> 
      <tr> 
       <td>run <span style="font-family: Courier New,Courier,monospace;">__libc_freeres()</span> on exit</td> 
       <td><p>This option is only relevant when running Valgrind on Linux.</p> <p>The GNU C library (<span style="font-family: Courier New,Courier,monospace;">libc.so</span>), which is used by all applications, can allocate memory for its own uses. Usually it does not free that memory when the application ends, since the Linux kernel reclaims all process resources when a process exits anyway. The glibc authors realized that this behavior causes leak checkers, such as Valgrind, to falsely report leaks in glibc, when a leak check is done at exit. In order to avoid this, they provided a routine called <span style="font-family: Courier New,Courier,monospace;">__libc_freeres()</span> specifically to make glibc release all memory it has allocated. <strong>Memcheck</strong> therefore tries to run <span style="font-family: Courier New,Courier,monospace;">__libc_freeres()</span> at exit. Unfortunately, in some very old versions of glibc, <span style="font-family: Courier New,Courier,monospace;">__libc_freeres()</span> is sufficiently buggy to cause segmentation faults. This was particularly noticeable on Red Hat 7.1. So this option is provided in order to inhibit the run of <span style="font-family: Courier New,Courier,monospace;">__libc_freeres()</span>. If your application seems to run fine on Valgrind, but segfaults at exit, disabling this option can fix the problem, although at the cost of possibly falsely reporting space leaks in <span style="font-family: Courier New,Courier,monospace;">libc.so</span>. </p></td> 
      </tr> 
      <tr> 
       <td>demangle C++ names</td> 
       <td><p>Automatic demangling (decoding) of C++ names is enabled by default. When enabled, Valgrind attempts to translate encoded C++ names back to something approaching the original. The demangler handles symbols mangled by g++ versions 2.X, 3.X, and 4.X.</p> <p>An important fact about demangling is that method names mentioned in suppressions files must be in their mangled form. Valgrind does not demangle method names when searching for applicable suppressions, because to do otherwise would make suppression file contents dependent on the state of Valgrind&#39;s demangling machinery, and also slow down suppression matching.</p></td> 
      </tr> 
      <tr> 
       <td>num callers in stack trace</td> 
       <td>This option specifies the maximum number of entries shown in stack traces that identify application locations. Errors are commoned up using only the top four method locations (the place in the current method, and that of its 3 immediate callers). So this does not affect the total number of errors reported.<p></p> <p>The maximum value for this option is 50. Note that higher settings make Valgrind run more slowly and take more memory, but can be useful when working with applications with deeply-nested call chains.</p> </td> 
      </tr> 
      <tr> 
       <td>limit errors reported</td> 
       <td><p>When enabled, Valgrind stops reporting errors after 10,000,000 in total, or 1,000 different ones, have been seen. This is to stop the error tracking machinery from becoming a huge performance overhead in applications with many errors.</p></td> 
      </tr> 
      <tr> 
       <td>show errors below main</td> 
       <td><p>By default, stack traces for errors do not show any methods that appear beneath <span style="font-family: Courier New,Courier,monospace;">main()</span>. Alternatively, if <span style="font-family: Courier New,Courier,monospace;">main()</span> is not present in the stack trace, it does not show any methods below <span style="font-family: Courier New,Courier,monospace;">main()</span>-like methods, such as glibc&#39;s <span style="font-family: Courier New,Courier,monospace;">__libc_start_main()</span>. Furthermore, if <span style="font-family: Courier New,Courier,monospace;">main()</span>-like methods are present in the trace, they are normalized as (below <span style="font-family: Courier New,Courier,monospace;">main()</span>), in order to make the output more deterministic. If this option is enabled, all stack trace entries are shown and <span style="font-family: Courier New,Courier,monospace;">main()</span>-like methods are not normalized.</p> </td> 
      </tr> 
      <tr> 
       <td>max size of stack frame</td> 
       <td><p>This option specifies the maximum size of a stack frame. If the stack pointer moves by more than this amount, Valgrind assumes that the application is switching to a different stack.</p> <p>You can to use this option if your application has large stack-allocated arrays. Valgrind keeps track of your application&#39;s stack pointer. If it changes by more than the threshold amount, Valgrind assumes your application is switching to a different stack, and <strong>Memcheck</strong> behaves differently than it would for a stack pointer change smaller than the threshold. Usually this heuristic works well. However, if your application allocates large structures on the stack, this heuristic is fooled, and <strong>Memcheck</strong> subsequently reports large numbers of invalid stack accesses. This option allows you to change the threshold to a different value.</p> <p>You must only consider the use of this option if Valgrind&#39;s debug output directs you to do so. In that case, it tells you the new threshold you must specify.</p> <p>In general, allocating large structures on the stack is a bad idea, because you can easily run out of stack space, especially on systems with limited memory or which expect to support large numbers of threads each with a small stack, and also because the error checking performed by <strong>Memcheck</strong> is more effective for heap-allocated data than for stack-allocated data. If you have to use this option, consider rewriting your code to allocate on the heap rather than on the stack.</p> </td> 
      </tr> 
      <tr> 
       <td>suppressions file</td> 
       <td><p>This option specifies an extra file from which to read descriptions of errors to suppress. You can use up to 100 extra suppression files.</p></td> 
      </tr> 
     </tbody> 
    </table></li> 
   <li><p>On the <strong>Tool Advanced setting</strong> tab, set the advanced options.</p> <p>The tab content depends on the selection you have made on the <strong>Collect data</strong> tab.</p> 
    <table style="width: 100%" border="1"> 
     <caption>
       Table: Tool Advanced setting options for memory error and memory leak profiling 
     </caption> 
     <tbody> 
      <tr> 
       <th rowspan="1" style="text-align:center;margin-left:auto;margin-right:auto;">Option name</th> 
       <th colspan="1" style="text-align:center;margin-left:auto;margin-right:auto;">Description</th> 
      </tr> 
      <tr> 
       <td>leak check</td> 
       <td><p>This option, when enabled, searches for memory leaks when the client application finishes. If set to summary, it lists out how many leaks occurred. If set to full or yes, it also gives details of each individual leak.</p> </td> 
      </tr> 
      <tr> 
       <td>leak resolution</td> 
       <td><p>When performing leak checks, this option determines how willing <strong>Memcheck</strong> is to consider different backtraces to be the same for the purposes of merging multiple leaks into a single leak report. When set to low, only the first 2 entries need match. When set to med, 4 entries have to match. When high, all entries need to match.</p> <p>For hardcore leak debugging, you probably want to use --leak-resolution=high together with --num-callers=40 or a similar large number. The --leak-resolution setting does not affect <strong>Memcheck</strong>&#39;s ability to find leaks. It only changes how the results are presented.</p> </td> 
      </tr> 
      <tr> 
       <td>freelist size (blocks)</td> 
       <td><p>When the client application releases memory using free (in C) or delete (C++), that memory is not immediately made available for re-allocation. Instead, it is marked inaccessible and placed in a queue of freed blocks. The purpose is to defer as long as possible the point at which freed-up memory comes back into circulation. This increases the chance that <strong>Memcheck</strong> is able to detect invalid accesses to blocks for some significant period of time after they have been freed.</p> <p>This option specifies the maximum total size, in bytes, of the blocks in the queue. The default value is 20 million bytes. Increasing this increases the total amount of memory used by <strong>Memcheck</strong>, but can result in the detection of invalid uses of freed blocks which would otherwise go undetected.</p> </td> 
      </tr> 
      <tr> 
       <td>show reachable blocks</td> 
       <td><p>When disabled, the memory leak detector only shows &quot;definitely lost&quot; and &quot;possibly lost&quot; blocks. When enabled, the leak detector also shows &quot;reachable&quot; and &quot;indirectly lost&quot; blocks. It shows all blocks, except suppressed ones, so --show-all would be a better name for it.</p> </td> 
      </tr> 
      <tr> 
       <td>allow partial loads</td> 
       <td><p>This option controls how <strong>Memcheck</strong> handles word-sized, word-aligned loads from addresses for which some bytes are addressable and others are not. When set to yes, such loads do not produce an address error. Instead, loaded bytes originating from illegal addresses are marked as uninitialized, and those corresponding to legal addresses are handled in the normal way.</p> <p>When set to no, loads from partially invalid addresses are treated the same as loads from completely invalid addresses, an illegal-address error is issued, and the resulting bytes are marked as initialized.</p> <p>The code that behaves in this way is in violation of the ISO C/C++ standards, and must be considered broken. If at all possible, such code must be fixed. This option must be used only as a last resort.</p> </td> 
      </tr> 
      <tr> 
       <td>undef value errors</td> 
       <td>This option controls whether <strong>Memcheck</strong> reports uses of undefined value errors. If you do not want to see undefined value errors, set this to no. It also has the side effect of slightly speeding up <strong>Memcheck</strong>.<p></p> </td> 
      </tr> 
     </tbody> 
    </table> 
    <table style="width: 100%" border="1"> 
     <caption>
       Table: Tool Advanced setting options for heap memory profiling 
     </caption> 
     <tbody> 
      <tr> 
       <th rowspan="1" style="text-align:center;margin-left:auto;margin-right:auto;">Option name</th> 
       <th colspan="1" style="text-align:center;margin-left:auto;margin-right:auto;">Description</th> 
      </tr> 
      <tr> 
       <td>profile heap</td> 
       <td><p>This option specifies whether heap profiling is done.</p> </td> 
      </tr> 
      <tr> 
       <td>administrative bytes per block</td> 
       <td><p>If heap profiling is enabled, this option gives the number of administrative bytes per block to use. This must be an estimate of the average, since it can vary. For example, the allocator used by glibc on Linux requires somewhere between 4 to 15 bytes per block, depending on various factors. That allocator also requires admin space for freed blocks, but <strong>Massif</strong> cannot account for this.</p> </td> 
      </tr> 
      <tr> 
       <td>profile stack</td> 
       <td><p>This option specifies whether stack profiling must be done. This option slows <strong>Massif</strong> down greatly, and so is off by default. <strong>Massif</strong> assumes that the main stack has size zero at start-up. This is not true, but doing otherwise accurately is difficult. Furthermore, starting at zero better indicates the size of the part of the main stack that a user application actually has control over.</p> </td> 
      </tr> 
      <tr> 
       <td>allocation tree depth</td> 
        <td><p>The maximum depth of the allocation trees recorded for detailed snapshots. Increasing it makes <strong>Massif</strong> run somewhat more slowly, use more memory, and produce bigger output files.</p> </td> 
      </tr> 
      <tr> 
       <td>heap allocation threshold</td> 
       <td><p>The significance threshold for heap allocations is a percentage of the total memory size. The allocation tree entries that account for less than this are aggregated. This must be specified in tandem with ms_print&#39;s option of the same name.</p> </td> 
      </tr> 
      <tr> 
       <td>allocation peak inaccuracy</td> 
       <td><p><strong>Massif</strong> does not necessarily record the actual global memory allocation peak. By default, it records a peak only when the global memory allocation size exceeds the previous peak by at least 1.0%. This is because there can be many local allocation peaks along the way, and doing a detailed snapshot for every one is expensive and wasteful, as all but one of them are later discarded. This inaccuracy can be changed (even to 0.0%) through this option, but <strong>Massif</strong> runs drastically slower as the number approaches zero.</p> </td> 
      </tr> 
      <tr> 
       <td>time unit</td> 
       <td><p>This option specifies the time unit used for the profiling. There are 3 possibilities: </p> 
        <ul> 
         <li>Instructions executed (i) <p>Good for most cases</p> </li> 
         <li>Real (wall clock) time (in milliseconds) <p>It is useful sometimes</p> </li> 
         <li>Bytes allocated/deallocated on the heap and/or stack (B) <p>It is useful for very short-run programs, and for testing purposes, because it is the most reproducible across different machines.</p> </li> 
        </ul></td> 
      </tr> 
      <tr> 
       <td>detailed snapshot frequency</td> 
       <td><p>This option specifies the frequency of detailed snapshots. With --detailed-freq=1, every snapshot is detailed.</p> </td> 
      </tr> 
      <tr> 
       <td>max snapshots</td> 
       <td><p>This option specifies the maximum number of snapshots recorded. If set to N, for all programs except very short-running ones, the final number of snapshots is between N/2 and N.</p> </td> 
      </tr> 
      <tr> 
       <td>minimum heap block alignment</td> 
       <td><p>By default, Valgrind&#39;s malloc, realloc, and so on return a block whose starting address is 8-byte-aligned or 16-byte-aligned. The value depends on the platform and matches the platform default. This option allows you to specify a different alignment. The supplied value must be greater than or equal to the default, less than or equal to 4096, and must be a power of 2.</p> </td> 
      </tr> 
      <tr> 
       <td>allocation functions</td> 
       <td><p>Methods specified with this option are treated as though they were a heap allocation method, such as malloc. This is useful for methods that are wrappers to malloc or new, which can fill up the allocation trees with uninteresting information. This option can be specified multiple times on the command line, to name multiple methods.</p> <p>The named method is only treated this way if it is the top entry in a stack trace, or just below another method treated this way. For example, if you have a method malloc1 that wraps malloc, and malloc2 that wraps malloc1, just specifying --alloc-fn=malloc2 has no effect. You need to specify --alloc-fn=malloc1 as well. This is a little inconvenient, but the reason is that checking for allocation method is slow, and it saves a lot of time if <strong>Massif</strong> can stop looking through the stack trace entries as soon as it finds one that does not match rather than having to continue through all the entries.</p> </td> 
      </tr> 
     </tbody> 
    </table> </li> 
   <li>To save the settings, click <strong>Apply</strong>.</li> 
   <li>To run Valgrind, click <strong>Profile</strong>.</li> 
  </ol>
 
<h3 id="valgrind_result" name="valgrind_result">Viewing Valgrind Result</h3> 
  <p>After the <a href="#running_valgrind">memory profiling</a> is terminated, you can view the profiling results.</p> 
  <h4 id="memleak" name="memleak">Memory Error and Leak Results</h4> 
  <p>The memory error table displays memory leaks that occurred during the profiling process.</p> 

  <ul> 
   <li><strong>Memory error</strong> or <strong>Memory leak</strong> is the error or leak type.</li> 
   <li><strong>Function name</strong> is the location where the error occurred.</li> 
   <li><strong>Sizes</strong> is the memory size of the error.</li> 
   <li><strong>Address</strong> is the code memory address.</li> 
   <li><strong>Location</strong> is the source or executable path, or library path, where the error occurred.</li> 
   <li><strong>pid</strong> is the process ID, and <strong>tid</strong> is the thread ID.<p></p> </li> 
  </ul> 
  <p>If you expand an error entry, you can see the callstack of the method.</p> 
  <h4 id="heap" name="heap">Heap Memory Profiling Results</h4> 
  <p>The heap memory profiling table displays the heap memory consumed and allocated during the profiling process.</p> 
  <p class="figure">Figure: Heap memory profiling results</p> 
  <p align="center"><img alt="Heap memory profiling results" src="../../images/valgrind_heap.png" /></p> 
  <ul> 
   <li><strong>Snapshot</strong> is the index number of the snapshot.</li> 
   <li><strong>Time (i)</strong> is the number of instructions being executed.</li> 
   <li><strong>Total (B)</strong> is the total heap memory consumption byte size.</li> 
   <li><strong>Useful Heap (B)</strong> is the size of the heap memory used by the program.</li> 
   <li><strong>Extra Heap (B)</strong> is the size of the heap memory allocated in excess of what the program is using. The source of extra heap memory is: 
    <ul> 
     <li>Administrative bytes of the heap memory block</li> 
     <li>Aligned bytes of the requested memory size</li> 
    </ul> </li> 
   <li><strong>Stack (B)</strong> is the size of the stacks. By default, stack profiling is disabled as it slows profiling. It is enabled using the <strong>profile stack</strong> option.</li> 
  </ul> 
  <p>A snapshot with a green icon in front has a heap tree with a callstack. Double-click the entry to see the callstack details.</p> 
  <p>For information on executing Valgrind on the command line interface, see the <a href="http://valgrind.org/docs/manual/manual.html" target="_blank">Valgrind User Manual</a>.</p>

  <h4 id="manage" name="manage">Managing Results</h4>
  <p>To save a Valgrind profiling result, click <strong>Save file</strong> on the Valgrind result view toolbar.</p> 

  <p>To load a saved Valgrind result file, select <strong>File &gt; Open File</strong> in the IDE menu.</p>  
  
   
  
  
<script type="text/javascript" src="../../scripts/jquery.zclip.min.js"></script>
<script type="text/javascript" src="../../scripts/showhide.js"></script>
</div></div></div>

<a class="top sms" href="#"><img src="../../images/btn_top.gif" alt="Go to top" /></a>

<div id="footer">
<p class="footer">Except as noted, this content - excluding the Code Examples - is licensed under <a href="http://creativecommons.org/licenses/by/3.0/legalcode" target="_blank">Creative Commons Attribution 3.0</a> and all of the Code Examples contained herein are licensed under <a href="https://www.tizen.org/bsd-3-clause-license" target="_blank">BSD-3-Clause</a>.<br/>For details, see the <a href="https://www.tizen.org/content-license" target="_blank">Content License</a>.</p>
</div>

<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-25976949-1']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>

</body>
</html>