<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=9" />
    <link rel="stylesheet" type="text/css" href="../../../css/styles.css" />
    <link rel="stylesheet" type="text/css" href="../../../css/snippet.css" />
    <script type="text/javascript" src="../../../scripts/snippet.js"></script>
    <script type="text/javascript" src="../../../scripts/jquery.util.js" charset="utf-8"></script>
    <script type="text/javascript" src="../../../scripts/common.js" charset="utf-8"></script>
    <script type="text/javascript" src="../../../scripts/core.js" charset="utf-8"></script>
    <script type="text/javascript" src="../../../scripts/search.js" charset="utf-8"></script>

    <title>Web Audio: Playing Audio Content</title>
</head>

<body onload="prettyPrint()" style="overflow: auto;">

<div id="toc-navigation">
    <div id="profile">
        <p><img alt="Mobile Web" src="../../../images/mobile_s_w.png"/></p>
    </div>
    <div id="toc_border"><div id="toc">
		<p class="toc-title">Content</p>
		<ul class="toc">
			<li><a href="#load">Loading Data and Creating Audio Context</a></li>
			<li><a href="#use">Using Modular Routing</a></li>
			<li><a href="#play">Playing Sound</a></li>
		</ul>
        <p class="toc-title">Related Info</p>
        <ul class="toc">
            <li><a href="../../../../../org.tizen.guides/html/web/w3c/media/webaudio_w.htm">Web Audio Guide</a></li>
			<li><a href="../../../../../org.tizen.web.apireference/html/w3c_api/w3c_api_m.html#webaudio">Web Audio API for Mobile Web</a></li>
        </ul>
    </div></div>
</div>

<div id="container"><div id="contents"><div class="content">
<h1>Web Audio: Playing Audio Content</h1>
  
 <p>This tutorial demonstrates how you can play audio content using the Web audio.</p>
 
<p>This feature is supported in mobile applications only.</p>


<h2>Warm-up</h2>
<p>Become familiar with the Web Audio API basics by learning about: </p>
<ul>
<li><a href="#load">Loading Source Data and Creating Audio Context</a>
<p>Modulate the source data into decoded audio data using <a href="../../../../../org.tizen.guides/html/web/w3c/communication/xmlhttprequest_w.htm">XMLHttpRequest</a>, and create an instance of <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioContext-section" target="_blank">AudioContext</a>.</p></li>
<li><a href="#use">Using Modular Routing</a>
<p>Connect to a modular routing node after creating other nodes, such as source node, filter node, and gain node.</p></li>
<li><a href="#play">Playing Sound</a>
<p>Play sound by using the <span style="font-family: Courier New,Courier,monospace">noteOn()</span> method.</p></li>
</ul>

 <h2 id="load" name="load">Loading Data and Creating Audio Context</h2>

<p>To provide users with sophisticated audio features, you must learn to modulate source data into decoded audio data using <a href="../../../../../org.tizen.guides/html/web/w3c/communication/xmlhttprequest_w.htm">XMLHttpRequest</a>, and create an instance of the <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioContext-section" target="_blank">AudioContext</a> interface:</p>

<ol>
<li>To load source audio data:
<ol type="a">
<li><p>Load a source audio file using XMLHttpRequest. Set the <span style="font-family: Courier New,Courier,monospace">responseType</span> to <span style="font-family: Courier New,Courier,monospace">arraybuffer</span> to receive binary response:</p>
<pre class="prettyprint">
&lt;script&gt;
&nbsp;&nbsp;&nbsp;var url = &quot;sample.mp3&quot;;
&nbsp;&nbsp;&nbsp;var request = new XMLHttpRequest();
&nbsp;&nbsp;&nbsp;request.open(&quot;GET&quot;, url, true);
&nbsp;&nbsp;&nbsp;request.responseType = &quot;arraybuffer&quot;;

&nbsp;&nbsp;&nbsp;request.send();
&lt;/script&gt;
</pre>
</li>

<li><p>The <span style="font-family: Courier New,Courier,monospace">onload</span> event is triggered. Retrieve the decoded audio data:</p>
<pre class="prettyprint">
&lt;script&gt;
&nbsp;&nbsp;&nbsp;/* Asynchronous event handling */
&nbsp;&nbsp;&nbsp;request.onload = function() 
&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Put the modulated audio data into the audioData variable */ 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var audioData = request.response;
&nbsp;&nbsp;&nbsp;};
&lt;/script&gt;
</pre>
<p>This data is used in the <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioBuffer-section" target="_blank">AudioBuffer</a>.</p>
</li>
</ol>
</li>
<li>To create an audio context:
<p>Create a WebKit-based <span style="font-family: Courier New,Courier,monospace">AudioContext</span> instance, which plays and manages the audio data:</p>
<pre class="prettyprint">
&lt;script&gt;
&nbsp;&nbsp;&nbsp;var context;
&nbsp;&nbsp;&nbsp;context = new webkitAudioContext();
&lt;/script&gt;
</pre>
<p>AudioContext instance supports various sound inputs, and it is possible to create an audio graph. You can create 1 or more sound sources to manage sound and connect to the sound destination.</p>
<p>The majority of the Web Audio API features, such as creating audio file data, decoding it, and creating <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioNode-section" target="_blank">AudioNodes</a> are managed using the methods of the <span style="font-family: Courier New,Courier,monospace">AudioContext</span> interface.</p>
</li>

<li>To create an audio buffer:
<p>Create an <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioBuffer-section" target="_blank">AudioBuffer</a> interface using the array buffer of audio data response attributes of the <span style="font-family: Courier New,Courier,monospace">XMLHttpRequest()</span> method. Select from the following options:</p>
<ul>
<li><p>Create the audio buffer using the <span style="font-family: Courier New,Courier,monospace">createBuffer()</span> method:</p>
<pre class="prettyprint">
&lt;script&gt;
&nbsp;&nbsp;&nbsp;var context = new webkitAudioContext();
&nbsp;&nbsp;&nbsp;function setSound()
&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var url = &quot;sample_audio.mp3&quot;;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var request = new XMLHttpRequest();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;request.open(&quot;GET&quot;, url, true);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;request.responseType = &quot;arraybuffer&quot;;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Asynchronous callback */
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;request.onload = function()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Create the sound source */
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource = context.createBufferSource();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundBuffer = context.createBuffer(request.response, true);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.buffer = soundBuffer;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;request.send();
&nbsp;&nbsp;&nbsp;}	
&lt;/script&gt;
</pre>
<p>The <span style="font-family: Courier New,Courier,monospace">createBuffer()</span> method is used as a synchronous decoding method to create an audio buffer of the required size.</p>
</li>

<li><p>Create the audio buffer using the <span style="font-family: Courier New,Courier,monospace">decodeAudioData()</span> method:</p>
<pre class="prettyprint">
&lt;script&gt;
&nbsp;&nbsp;&nbsp;var context = new webkitAudioContext();
&nbsp;&nbsp;&nbsp;function setSound()
&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var url = &quot;sample_audio.mp3&quot;;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var request = new XMLHttpRequest();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;request.open(&quot;GET&quot;, url, true);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;request.responseType = &quot;arraybuffer&quot;;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Asynchronous callback */
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;request.onload = function()
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Create the sound source */
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource = context.createBufferSource();
            
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Import callback function that provides PCM audio data decoded as an audio buffer */
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;context.decodeAudioData(request.response, function(buffer)
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bufferData = buffer;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.buffer = bufferData;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}, this.onDecodeError);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;};
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;request.send();
&nbsp;&nbsp;&nbsp;}
&lt;/script&gt;
</pre>
<p>The <span style="font-family: Courier New,Courier,monospace">decodeAudioData()</span> method asynchronously decodes audio data from the <a href="../../../../../org.tizen.guides/html/web/w3c/communication/xmlhttprequest_w.htm">XMLHttpRequest</a> array buffer. Since this method does not prevent the execution of JavaScript threads, consider using it instead of the <span style="font-family: Courier New,Courier,monospace">createBuffer()</span> method.</p>
</li>
</ul>
<p>To use an audio buffer created with the <span style="font-family: Courier New,Courier,monospace">createBuffer()</span> or <span style="font-family: Courier New,Courier,monospace">decodeAudioData()</span> method, the buffer must be allocated to the <span style="font-family: Courier New,Courier,monospace">audioBufferSourceNode</span> buffer.</p>
</li>
</ol>

 <h3>Source Code</h3>
	<p>For the complete source code related to this use case, see the following file:</p>
 <ul>
	<li><a href="http://download.tizen.org/misc/examples/w3c_html5/media/web_audio_api" target="_blank">web_audio_basic_playback.html</a></li>
 </ul>
   			
 <h2 id="use" name="use">Using Modular Routing</h2>

<p>To provide users with sophisticated audio features, you must learn to enable routing audio source data using <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioNode-section" target="_blank">AudioNode</a> objects:</p>

<ol>
<li>To route to speaker output in a direct sound destination:
<ol type="a">
<li><p>Create a WebKit-based <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioContext-section" target="_blank">AudioContext</a> instance:</p>
<pre class="prettyprint">
&lt;script&gt;
&nbsp;&nbsp;&nbsp;var context;
&nbsp;&nbsp;&nbsp;context = new webkitAudioContext();
</pre>
</li>
<li><p>Route a single audio source directly to the output:</p>
<pre class="prettyprint">
&nbsp;&nbsp;&nbsp;var soundSource;

&nbsp;&nbsp;&nbsp;function startSound(audioData) 
&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource = context.createBufferSource();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.buffer = soundBuffer;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/* Direct routing to speaker */ 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.connect(volumeNode);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;volumeNode.connect(context.destination);
&nbsp;&nbsp;&nbsp;}
&lt;/script&gt;
</pre>
<p>All routing occurs within an <span style="font-family: Courier New,Courier,monospace">AudioContext</span> containing a single <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioDestinationNode-section" target="_blank">AudioDestinationNode</a>.</p>
 
<p align="center"><img alt="Direct routing" src="../../../images/web_audio1.png" /></p>
</li>
</ol>
</li>

<li><p>To route to the sound destination using <span style="font-family: Courier New,Courier,monospace">AudioNodes</span>:</p>
<ol type="a">
<li><p>Create an <span style="font-family: Courier New,Courier,monospace">AudioContext</span> instance:</p>
<pre class="prettyprint">
&lt;script&gt;
&nbsp;&nbsp;&nbsp;var context;
&nbsp;&nbsp;&nbsp;context = new webkitAudioContext();
</pre>
</li>
<li><p>Create the sound source:</p>
<pre class="prettyprint lang-js">
&nbsp;&nbsp;&nbsp;function startSound(audioData) 
&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource = context.createBufferSource();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundBuffer = context.createBuffer(audioData, true);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.buffer = soundBuffer;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;volumeNode = context.createGainNode();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;filter = context.createBiquadFilter();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;audioAnalyser = context.createAnalyser();

</pre>
</li>
<li><p>Create the node to manage the output, for example, adjusting volume and applying filters:</p>
<pre class="prettyprint lang-js">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.connect(volumeNode);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;volumeNode.connect(filter);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;filter.connect(audioAnalyser);
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;audioAnalyser.connect(context.destination);
&nbsp;&nbsp;&nbsp;}
&lt;/script&gt;
</pre>

<p>The figure below illustrates using 3 sources and a convolution reverb sent with a dynamics compressor at the final output stage.</p>

<p align="center"><img alt="Routing from multiple sources" src="../../../images/web_audio2.png" /></p> 
</li>
</ol>
</li>
</ol>
<p><span style="font-family: Courier New,Courier,monospace">AudioNodes</span> can be used to activate sound effects, and create tweaks, audio parameters, and audio graphs using the <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#GainNode-section" target="_blank">GainNode</a> interface, or filter sounds using the <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#BiquadFilterNode" target="_blank">BiquadFilterNode</a> interface.</p>
 
  <h3>Source Code</h3>
	<p>For the complete source code related to this use case, see the following file:</p>
 <ul>
	<li><a href="http://download.tizen.org/misc/examples/w3c_html5/media/web_audio_api" target="_blank">web_audio_basic_playback.html</a></li>
 </ul>
   		
 <h2 id="play" name="play">Playing Sound</h2>
 
 <p>To provide users with sophisticated audio features, you must learn to play sound:</p>
<ol>
<li><p>Create a WebKit-based <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioContext-section" target="_blank">AudioContext</a> instance:</p>
<pre class="prettyprint">
&lt;script&gt;
&nbsp;&nbsp;&nbsp;var context;
&nbsp;&nbsp;&nbsp;context = new webkitAudioContext();</pre>
</li>
<li><p>Play audio through direct sound destination using the <span style="font-family: Courier New,Courier,monospace">noteOn()</span> method:</p>
<pre class="prettyprint">
&nbsp;&nbsp;&nbsp;function playSound() 
&nbsp;&nbsp;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var soundSource = context.createBufferSource();
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.buffer = soundBuffer;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.connect(context.destination); 
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;soundSource.noteOn(context.currentTime);
&nbsp;&nbsp;&nbsp;} 
&lt;/script&gt;
</pre>
<p>Use time as parameter of the <span style="font-family: Courier New,Courier,monospace">noteOn()</span> method. Time is based on the <span style="font-family: Courier New,Courier,monospace">currentTime</span> property of the <span style="font-family: Courier New,Courier,monospace">AudioContext</span>, and expressed in seconds. If you set the value as &#39;0&#39;, the playback begins immediately.</p>

<p>You can also use time as parameter of the <span style="font-family: Courier New,Courier,monospace">noteOff()</span> method. If you set the value as &#39;0&#39;, the playback stops immediately.</p>
</li>
</ol>

<p>The <span style="font-family: Courier New,Courier,monospace">AudioContext</span> instance digitally modulates the audio source file into audio data. After creating the sound source, playback is implemented by processing audio data using <a href="http://www.w3.org/TR/2012/WD-webaudio-20121213/#AudioNode-section" target="_blank">AudioNodes</a> either directly to the speaker, or in the middle.</p>

 <h3>Source Code</h3>
	<p>For the complete source code related to this use case, see the following file:</p>
 <ul>
	<li><a href="http://download.tizen.org/misc/examples/w3c_html5/media/web_audio_api" target="_blank">web_audio_basic_playback.html</a></li>
 </ul>
     	
           
<script type="text/javascript" src="../../../scripts/jquery.zclip.min.js"></script>
<script type="text/javascript" src="../../../scripts/showhide.js"></script>

</div></div></div>

<a class="top sms" href="#"><img src="../../../images/btn_top.gif" alt="Go to top" /></a>

<div id="footer">
<p class="footer">Except as noted, this content - excluding the Code Examples - is licensed under <a href="http://creativecommons.org/licenses/by/3.0/legalcode" target="_blank">Creative Commons Attribution 3.0</a> and all of the Code Examples contained herein are licensed under <a href="https://www.tizen.org/bsd-3-clause-license" target="_blank">BSD-3-Clause</a>.<br/>For details, see the <a href="https://www.tizen.org/content-license" target="_blank">Content License</a>.</p>
</div>

<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-25976949-1']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>

</body>
</html>
